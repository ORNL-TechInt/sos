Exploratory Analysis to Support Visualization
=============================================

Description
-----------
The HPC visualization process is still guided by scientific intuition and
direct user feedback.  The process involves siginificant user-guided
interactions with large amounts of data and is not yet a workflow with much
automation.

Actors
------
1.  Sam, a computational nuclear scientist
2.  Victor, a visualization expert
3.  SOS, an object storage system
4.  Lens, a visualization compute cluster
5.  VisiT, a visualization toolkit
6.  Everest, a render cluster
7.  Maya, a rendering package


Assumptions
-----------
The storage system contains a scientific data set of thousands of files
totaling 500 TB. 

Steps
-----
1. Sam, a nuclear scientist, contacts Victor to help visualize a phenomenon in
his data set generated by his Nuk'Em code.
2. Victor launches a ViSiT job on Lens, the exploratory analysis viz cluster.
  Lens is limited in memory and can not hold all of the data set in memory at
  once. The ratio of Lens' memory to the total data set size is 1:80.
  2.1 The ViSiT processes open all the files, read a small portion of each file,
      trying to learn about a trend of a small of variables. 
  2.2 Sam and Victor examine the event for interest and will continue examining
      the event iteratively until they found an interesting event.  The search
      for events does not result in a sequential I/O load (necessarily). The
      size of the events practically is not predicted in advance. The range is
      from small to large block sizes. 
  2.3 Sam and Victor identify an interesting event and catalogue the event for
      rendering. 
  2.4 Sam and Victor using ViSiT takes regions of interest from thousands of raw
      data files open and reformat into tens of files (roughly 1:50 size reduction)
      and write it out to the object storage system. 
3.  In order to render the data for presentation, Victor launches a job on
  Everest to access the reduced data set coming out of exploratory analysis
  stage. 
  3.1 The Maya/Blender job reads the reduced data set into the memory until its full.
  3.2 Maya/Blender processes the data and writes out image frames (a few MBs
      each) until the loaded data is processed.
  3.3 Maya/Blender repeats steps 3.1 and 3.2 until the full reduced data set has
      been scanned and processed. 
  3.4 The resulting movie file size will be around few hundred GB.

Variations
----------
1. The initial scientific format can be Adios BP, netCDF, Silo, or HDF5.
2. Event size depends on the domain science needs and may range from 4 kB to 4 MB.
2. Tools used to explore data may be ViSiT, Insight, Matlab, or R.
6. ViSiT handles fixed size blocks much more than it can handle irregular data
   much more efficiently. 
3. Exploratory output file format will depend on the exploratory tool used.
4. The total memory size of the exploratory analysis cluster.
5. Output frames sizes will depend on the frame type.
7. When the data sizes is larger than the memory footprint of the viz cluster,
   than the exploratory analysis must be done on a leadership system. This
   process is highly interactive (which is typically difficult with these systems).  



